{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class PreProcessing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, dataset):\n",
    "\n",
    "        dataset = dataset.drop(['Ticket', 'Cabin'], axis=1)\n",
    "        dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "        dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "                                                         'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "        dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "        dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "        dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "        title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "        dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "        dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "        dataset = dataset.drop(['Name'], axis=1)\n",
    "\n",
    "        dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "        '''\n",
    "        guess_ages = np.zeros((2,3))\n",
    "        for i in range(0, 2):\n",
    "            for j in range(0, 3):\n",
    "                guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                      (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "                age_guess = guess_df.median()\n",
    "\n",
    "                # Convert random age float to nearest .5 age\n",
    "                guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "\n",
    "        for i in range(0, 2):\n",
    "            for j in range(0, 3):\n",
    "                dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                        'Age'] = guess_ages[i,j]\n",
    "        '''\n",
    "        dataset['Age'] = dataset['Age'].fillna(40).astype(int)\n",
    "\n",
    "        dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "        dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "        dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "        dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "        dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
    "\n",
    "        dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "        dataset['IsAlone'] = 0\n",
    "        dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "        dataset = dataset.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "\n",
    "        dataset['Age*Class'] = dataset.Age * dataset.Pclass\n",
    "\n",
    "        dataset['Embarked'] = dataset['Embarked'].fillna(\"S\")\n",
    "\n",
    "        dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "        dataset['Fare'].fillna(dataset['Fare'].dropna().median(), inplace=True)\n",
    "\n",
    "        dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "        dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "        dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "        dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "        dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "        return dataset.as_matrix()\n",
    "    \n",
    "    def fit(self, dataset, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessing', PreProcessing()), ('RF', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('preprocessing', PreProcessing()), ('RF', RandomForestClassifier())])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "X_train = df_train.drop([\"Survived\", \"PassengerId\"], axis=1)\n",
    "Y_train = df_train[\"Survived\"]\n",
    "X_test  = df_test.drop(\"PassengerId\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessing', PreProcessing()), ('RF', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(X_test.loc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "filename = 'model_v1.pk'\n",
    "with open('./model/'+filename, 'wb') as file:\n",
    "    pickle.dump(pipe, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./model/'+filename ,'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "loaded_model.predict(X_test.loc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
